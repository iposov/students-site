{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE Estimates: [(('an', ()), 0.5), (('apple', ()), 0.25)]\n",
      "MLE Estimates: [(('an', ()), 0.5), (('ant', ()), 0.0)]\n",
      "PP(an apple):2.8284271247461903\n",
      "PP(an ant):inf\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import MLE\n",
    "\n",
    "train_sentences = ['an apple', 'an orange']\n",
    "tokenized_text = [list(map(str.lower, nltk.tokenize.word_tokenize(sent)))\n",
    "                  for sent in train_sentences]\n",
    "n = 1\n",
    "train_data, padded_vocab = padded_everygram_pipeline(n, tokenized_text)\n",
    "model = MLE(n)\n",
    "model.fit(train_data, padded_vocab)\n",
    "\n",
    "test_sentences = ['an apple', 'an ant']\n",
    "tokenized_text = [list(map(str.lower, nltk.tokenize.word_tokenize(sent)))\n",
    "                  for sent in test_sentences]\n",
    "\n",
    "test_data, _ = padded_everygram_pipeline(n, tokenized_text)\n",
    "for test in test_data:\n",
    "    print (\"MLE Estimates:\", [((ngram[-1], ngram[:-1]),model.score(ngram[-1], ngram[:-1])) for ngram in test])\n",
    "\n",
    "test_data, _ = padded_everygram_pipeline(n, tokenized_text)\n",
    "\n",
    "for i, test in enumerate(test_data):\n",
    "    print(\"PP({0}):{1}\".format(test_sentences[i], model.perplexity(test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('<s>',), ('<s>', 'an'), ('an',), ('an', 'apple'), ('apple',), ('apple', '</s>'), ('</s>',)], [('<s>',), ('<s>', 'an'), ('an',), ('an', 'ant'), ('ant',), ('ant', '</s>'), ('</s>',)]] ['<s>', 'an', 'apple', '</s>', '<s>', 'an', 'ant', '</s>']\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "a, b = padded_everygram_pipeline(n, tokenized_text)\n",
    "print(list(list(x) for x in a), list(b))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Исследование n-грамм модели текста\n",
    "\n",
    "1. Создайте корпус текстов из нескольких литературных произведений, выберите хотя бы два больших текста\n",
    "ваших любимых писателей.\n",
    "2. Далее вам надо разбить текст на предложения (см. ранее `sent_tokenze`), соответственно, вы получаете\n",
    "   большой список предложений, которые мы будем использовать для исследований.\n",
    "3. Разбейте список предложений случайным образом на три части: для обучения (train set), для настройки\n",
    " (validation set), для тестирования качества (test set). Для этого перемешайте список предложений, возьмите\n",
    "  первые 80% как train set, следующие 10% как validation set, оставшиеся 10% как test set.\n",
    "\n",
    "  Пример кода для перемешивания:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['надо', 'слова', 'которые', 'перемешать', 'мы']\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle, seed\n",
    "\n",
    "# инициализация генератора случайных чисел, случайные числа все время будут\n",
    "# одинаковые, это удобно для отладки, после отладки эту строку надо убрать.\n",
    "seed(42)\n",
    "\n",
    "l = [\"мы\", \"слова\", \"которые\", \"надо\", \"перемешать\"]\n",
    "shuffle(l)\n",
    "print(l)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Предложения из всех трёх множеств нужно обработать. Для обучающего множества можно пользоваться\n",
    "  встроенной в nltk функцией `padded_everygram_pipeline`.\n",
    "\n",
    "  Эта функция делает сразу много действий, она дополняет предложения техническими словами `<s>` и `</s>`\n",
    "  для начала и конца, возвращает `n_grams`, который для каждого предложения содержит список всех n-грамм\n",
    "  этого предложения, причем, если мы указываем n=3 в качестве аргумента, будут построены и 1-, и 2-,\n",
    "  и 3-граммы. В `words` возвращается список всех слов, чтобы построить словарь на их основе:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "все слова:\n",
      "['<s>', '<s>', 'моё', 'первое', 'предложение', '!', '</s>', '</s>', '<s>', '<s>', 'моё', 'второе', 'предложение', '.', '</s>', '</s>', '<s>', '<s>', 'еще', 'одно', 'предложение', '.', '</s>', '</s>']\n",
      "все n-граммы\n",
      "[('<s>',), ('<s>', '<s>'), ('<s>', '<s>', 'моё'), ('<s>',), ('<s>', 'моё'), ('<s>', 'моё', 'первое'), ('моё',), ('моё', 'первое'), ('моё', 'первое', 'предложение'), ('первое',), ('первое', 'предложение'), ('первое', 'предложение', '!'), ('предложение',), ('предложение', '!'), ('предложение', '!', '</s>'), ('!',), ('!', '</s>'), ('!', '</s>', '</s>'), ('</s>',), ('</s>', '</s>'), ('</s>',)]\n",
      "[('<s>',), ('<s>', '<s>'), ('<s>', '<s>', 'моё'), ('<s>',), ('<s>', 'моё'), ('<s>', 'моё', 'второе'), ('моё',), ('моё', 'второе'), ('моё', 'второе', 'предложение'), ('второе',), ('второе', 'предложение'), ('второе', 'предложение', '.'), ('предложение',), ('предложение', '.'), ('предложение', '.', '</s>'), ('.',), ('.', '</s>'), ('.', '</s>', '</s>'), ('</s>',), ('</s>', '</s>'), ('</s>',)]\n",
      "[('<s>',), ('<s>', '<s>'), ('<s>', '<s>', 'еще'), ('<s>',), ('<s>', 'еще'), ('<s>', 'еще', 'одно'), ('еще',), ('еще', 'одно'), ('еще', 'одно', 'предложение'), ('одно',), ('одно', 'предложение'), ('одно', 'предложение', '.'), ('предложение',), ('предложение', '.'), ('предложение', '.', '</s>'), ('.',), ('.', '</s>'), ('.', '</s>', '</s>'), ('</s>',), ('</s>', '</s>'), ('</s>',)]\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    [\"моё\", \"первое\", \"предложение\", \"!\"],\n",
    "    [\"моё\", \"второе\", \"предложение\", \".\"],\n",
    "    [\"еще\", \"одно\", \"предложение\", \".\"]\n",
    "]\n",
    "\n",
    "n = 3\n",
    "n_grams, words = padded_everygram_pipeline(n, sentences)\n",
    "\n",
    "print(\"все слова:\")\n",
    "print(list(words)) # нужно делать list(), потому что words это генератор\n",
    "print(\"все n-граммы\")\n",
    "for sentence_n_grams in n_grams:\n",
    "    print(list(sentence_n_grams))  # нужно делать list(), потому что sentence_n_grams это генератор\n",
    "\n",
    "# небольшое замечание, padded_everygram_pipeline возвращает генераторы\n",
    "# их можно использовать только один раз. Например, их можно распечатать,\n",
    "# или можно обучить через них модель. После этого их надо\n",
    "# создавать заново. Вы можете столкнуться с этим при отладке,\n",
    "# модель не обучается после того, как вы всё распечатали."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. Настроечное и тестовое множество (validation) предложений\n",
    "   нужно обработать аналогично, добавить слова `<s>` и `<\\s>`,\n",
    "   вычислить n-граммы, причем в этот раз нас интересуют\n",
    "   n-граммы при фиксированном $n$."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '<s>', 'мы', 'слова', 'одного', 'предложения', '</s>', '</s>']\n",
      "[('<s>', '<s>', 'мы'), ('<s>', 'мы', 'слова'), ('мы', 'слова', 'одного'), ('слова', 'одного', 'предложения'), ('одного', 'предложения', '</s>'), ('предложения', '</s>', '</s>')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "from nltk import ngrams\n",
    "\n",
    "sentence = ['мы', 'слова', 'одного', 'предложения']\n",
    "padded_sentence = pad_both_ends(sentence, n)\n",
    "print(list(padded_sentence))\n",
    "\n",
    "# после распечатки padded_sentence стух\n",
    "padded_sentence = pad_both_ends(sentence, n)\n",
    "all_sentence_n_grams = ngrams(padded_sentence, n)\n",
    "print(list(all_sentence_n_grams))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "В принципе, рассмотренный выше `padded_everygram_pipeline` можно\n",
    "было реализовать самостоятельно через функции `pad_both_ends` и\n",
    "`ngrams`.\n",
    "\n",
    " 6. Обучаем модель. Точнее, несколько моделей с разными видами\n",
    "    сглаживания. Позже, мы будем их сравнивать."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from nltk.lm import MLE, Lidstone, KneserNeyInterpolated\n",
    "\n",
    "n_grams, words = padded_everygram_pipeline(n, sentences)\n",
    "# создаём модель\n",
    "model = MLE(n) # Модель MLE означает отсутствие сглаживания\n",
    "# обучаем\n",
    "model.fit(n_grams, words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Кроме модели `MLE(n)` можно создать модель `Lidstone(gamma, n)`,\n",
    "она означает модель, которую мы называли сглаживанием\n",
    "Лапласса, и здесь `gamma` означает число, добавляемое в числитель.\n",
    "\n",
    "Модель \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}