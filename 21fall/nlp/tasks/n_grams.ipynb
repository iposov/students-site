{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Исследование n-грамм модели текста\n",
    "\n",
    "### 1. Корпус\n",
    "Создайте корпус текстов из нескольких литературных произведений, выберите хотя бы два больших текста\n",
    "ваших любимых писателей.\n",
    "### 2. Обработка корпуса, выделение предложений\n",
    "Далее вам надо разбить текст на предложения (см. ранее `sent_tokenze`), соответственно, вы получаете\n",
    "   большой список предложений, которые мы будем использовать для исследований.\n",
    "### 3. Разделение на обучающее, настроечное, тестовое множества\n",
    "Разбейте список предложений случайным образом на три части: для обучения (train set), для настройки\n",
    " (validation set), для тестирования качества (test set). Для этого перемешайте список предложений, возьмите\n",
    "  первые 80% как train set, следующие 10% как validation set, оставшиеся 10% как test set.\n",
    "\n",
    "  Пример кода для перемешивания:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['надо', 'слова', 'которые', 'перемешать', 'мы']\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle, seed\n",
    "\n",
    "# инициализация генератора случайных чисел, случайные числа все время будут\n",
    "# одинаковые, это удобно для отладки, после отладки эту строку надо убрать.\n",
    "seed(42)\n",
    "\n",
    "l = [\"мы\", \"слова\", \"которые\", \"надо\", \"перемешать\"]\n",
    "shuffle(l)\n",
    "print(l)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Подготовка обучающего множества\n",
    "\n",
    "Предложения из всех трёх множеств нужно обработать. Для обучающего множества можно пользоваться\n",
    "  встроенной в nltk функцией `padded_everygram_pipeline`.\n",
    "\n",
    "  Эта функция делает сразу много действий, она дополняет предложения техническими словами `<s>` и `</s>`\n",
    "  для начала и конца, возвращает `n_grams`, который для каждого предложения содержит список всех n-грамм\n",
    "  этого предложения, причем, если мы указываем n=3 в качестве аргумента, будут построены и 1-, и 2-,\n",
    "  и 3-граммы. В `words` возвращается список всех слов, чтобы построить словарь на их основе:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "все слова:\n",
      "['<s>', '<s>', 'моё', 'первое', 'предложение', '!', '</s>', '</s>', '<s>', '<s>', 'моё', 'второе', 'предложение', '.', '</s>', '</s>', '<s>', '<s>', 'еще', 'одно', 'предложение', '.', '</s>', '</s>']\n",
      "все n-граммы\n",
      "[('<s>',), ('<s>', '<s>'), ('<s>', '<s>', 'моё'), ('<s>',), ('<s>', 'моё'), ('<s>', 'моё', 'первое'), ('моё',), ('моё', 'первое'), ('моё', 'первое', 'предложение'), ('первое',), ('первое', 'предложение'), ('первое', 'предложение', '!'), ('предложение',), ('предложение', '!'), ('предложение', '!', '</s>'), ('!',), ('!', '</s>'), ('!', '</s>', '</s>'), ('</s>',), ('</s>', '</s>'), ('</s>',)]\n",
      "[('<s>',), ('<s>', '<s>'), ('<s>', '<s>', 'моё'), ('<s>',), ('<s>', 'моё'), ('<s>', 'моё', 'второе'), ('моё',), ('моё', 'второе'), ('моё', 'второе', 'предложение'), ('второе',), ('второе', 'предложение'), ('второе', 'предложение', '.'), ('предложение',), ('предложение', '.'), ('предложение', '.', '</s>'), ('.',), ('.', '</s>'), ('.', '</s>', '</s>'), ('</s>',), ('</s>', '</s>'), ('</s>',)]\n",
      "[('<s>',), ('<s>', '<s>'), ('<s>', '<s>', 'еще'), ('<s>',), ('<s>', 'еще'), ('<s>', 'еще', 'одно'), ('еще',), ('еще', 'одно'), ('еще', 'одно', 'предложение'), ('одно',), ('одно', 'предложение'), ('одно', 'предложение', '.'), ('предложение',), ('предложение', '.'), ('предложение', '.', '</s>'), ('.',), ('.', '</s>'), ('.', '</s>', '</s>'), ('</s>',), ('</s>', '</s>'), ('</s>',)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "\n",
    "sentences = [\n",
    "    [\"моё\", \"первое\", \"предложение\", \"!\"],\n",
    "    [\"моё\", \"второе\", \"предложение\", \".\"],\n",
    "    [\"еще\", \"одно\", \"предложение\", \".\"]\n",
    "]\n",
    "\n",
    "n = 3\n",
    "n_grams, words = padded_everygram_pipeline(n, sentences)\n",
    "\n",
    "print(\"все слова:\")\n",
    "print(list(words)) # нужно делать list(), потому что words это генератор\n",
    "print(\"все n-граммы\")\n",
    "for sentence_n_grams in n_grams:\n",
    "    print(list(sentence_n_grams))  # нужно делать list(), потому что sentence_n_grams это генератор\n",
    "\n",
    "# небольшое замечание, padded_everygram_pipeline возвращает генераторы\n",
    "# их можно использовать (перебрать) только один раз. Например, их можно распечатать,\n",
    "# или можно обучить через них модель. После этого их надо\n",
    "# создавать заново. Вы можете столкнуться с этим при отладке,\n",
    "# модель не обучается после того, как вы всё распечатали."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Обработка настроечного и тестового множества\n",
    "\n",
    "   Настроечное и тестовое множество (validation) предложений\n",
    "   нужно обработать аналогично, добавить слова `<s>` и `<\\s>`,\n",
    "   вычислить n-граммы, причем в этот раз нас интересуют\n",
    "   n-граммы при фиксированном $n$."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '<s>', 'мы', 'слова', 'одного', 'предложения', '</s>', '</s>']\n",
      "[('<s>', '<s>', 'мы'), ('<s>', 'мы', 'слова'), ('мы', 'слова', 'одного'), ('слова', 'одного', 'предложения'), ('одного', 'предложения', '</s>'), ('предложения', '</s>', '</s>')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "from nltk import ngrams\n",
    "\n",
    "# сначала нужно добавить символы начала и конца предложения\n",
    "sentence = ['мы', 'слова', 'одного', 'предложения']\n",
    "padded_sentence = pad_both_ends(sentence, n)\n",
    "print(list(padded_sentence))\n",
    "\n",
    "# после распечатки padded_sentence стух, поэтому создадим его заново\n",
    "padded_sentence = pad_both_ends(sentence, n)\n",
    "all_sentence_n_grams = ngrams(padded_sentence, n)\n",
    "print(list(all_sentence_n_grams))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "В принципе, рассмотренный выше `padded_everygram_pipeline` можно\n",
    "было реализовать самостоятельно через функции `pad_both_ends` и\n",
    "`ngrams`.\n",
    "\n",
    "### 6. Обучение модели\n",
    "\n",
    "Обучаем модель. Точнее, несколько моделей с разными видами\n",
    "    сглаживания. Позже, мы будем их сравнивать."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from nltk.lm import MLE, Lidstone, KneserNeyInterpolated\n",
    "\n",
    "n_grams, words = padded_everygram_pipeline(n, sentences)\n",
    "# создаём модель\n",
    "model = MLE(n) # Модель MLE означает отсутствие сглаживания\n",
    "# обучаем\n",
    "model.fit(n_grams, words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Кроме модели `MLE(n)` можно создать модель `Lidstone(gamma, n)`,\n",
    "она означает модель, которую мы называли сглаживанием\n",
    "Лапласса, и здесь `gamma` означает число, добавляемое в числитель.\n",
    "\n",
    "Модель `KneserNeyInterpolated(n, 0.1)` соответствует модели со\n",
    "сглаживанием KneyserNey из конспекта. `discount` 0.1 означает число,\n",
    "вычитаемое из числителя.\n",
    "\n",
    "### 7. Оценка модели\n",
    "\n",
    "Когда модель построена, ее можно оценить, мы оцениваем все\n",
    "  модели на настроечном множестве (validation set). Для оценки\n",
    "  используем величину perplexity, она равна 1 делить на среднюю геометрическую\n",
    "  вероятностей всех n-грамм. Соответственно, чем perplexity меньше, тем больше средняя\n",
    "  вероятность n-грамм из текста, т.е. модель лучше предсказывает этот текст.\n",
    "  В коде вы можете вызвать `model.perplexity(all_sentence_n_grams)`, где\n",
    "  `all_sentence_n_grams` получен в пункте 5.\n",
    "\n",
    "### 8. Выбор лучшей модели\n",
    "Нам нужно выбрать лучшую модель, мы рассмотрим несколько моделей со сглаживанием Лапласа и\n",
    "  несколько моделей со сглаживанием Kneyser-Ney. MLE нас не интересует, потому что не имеет\n",
    "  сглаживание, и любое неизвестное слово или не встречавшееся ранее сочетание слов ведёт к\n",
    "  нулевой вероятности.\n",
    "\n",
    "  Рассмотрим модели Лапласа, где `gamma` выбирается как $0.1$, $0.2$, $0.5$, $1$, $2$. В моделях\n",
    "  Kneyser-Ney выбираем `discount` как $0.01$, $0.05$, $0.1$, $0.2$, $0.5$. Если вычисления окажутся\n",
    "  долгими, уменьшите количество вариантов.\n",
    "\n",
    "  Для каждой модели вычислите perplexity на настроечном множестве (validation set), выберите\n",
    "  минимальное значение.\n",
    "### 9. Окончательная оценка лучшей модели\n",
    "Для модели, которая выдаёт минимальное значение на настроечном множестве, вычислите perplexity\n",
    "  на тестовом множестве (test set). Это будет ответ, какую perplexity мы достигли\n",
    "  с помощью n-грамм модели."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}